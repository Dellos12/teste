{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIFNpmnRotQBA9a30RIFEJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dellos12/teste/blob/main/Untitled20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVnmQ6xR0dEE"
      },
      "outputs": [],
      "source": [
        "! pip install -q transformers datasets matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from datasets import load_dataset\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Definindo o dispositivo (GPU se disponível)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando: {device}\")"
      ],
      "metadata": {
        "id": "-uQm8JNE1OZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# 2. Carregar o Tokenizer e o Modelo Pré-treinado (BERTimbau)\n",
        "model_name = \"neuralmind/bert-base-portuguese-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name).to(device)\n",
        "\n",
        "# Criando dados de exemplo (Polos Positivos e Negativos) pra teste imediato\n",
        "frases = [\n",
        "    \"Este produto é maravilhoso, superou as expectativas!\", \"Amei cada detalhe.\",\n",
        "    \"Execelente atendimeto e qualidade impecável.\", \"Simplesmente incrível, recomendo muinto!\",\n",
        "    \"Horrivel, o poduto veio quebrado e atrasou.\", \"Pior experiência de compra que já tive.\",\n",
        "    \"Não funciona, dinheiro jogado fora.\", \"Atendimento péssimo e material de baixa qualidade.\"\n",
        "]\n",
        "# Labels: 1 para positivo, 0 negativo\n",
        "labels = [1, 1, 1, 1, 0, 0, 0, 0]"
      ],
      "metadata": {
        "id": "m8LRmuam2-6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Função para extrair os embeddings (vetores de 768 dimensôes)\n",
        "def get_embeddings(text_list):\n",
        "    model.eval()\n",
        "    embeddings = []\n",
        "    with torch.no_grad():\n",
        "        for text in text_list:\n",
        "            inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "            outputs = model(**inputs)\n",
        "            cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(cls_embedding)\n",
        "    return np.vstack(embeddings)\n",
        "\n",
        "vetores = get_embeddings(frases)\n",
        "print(f\"Formato da matriz de embeddings: {vetores.shape}\") # (8 frases, 768 dimensões)"
      ],
      "metadata": {
        "id": "JCwE4IrXD7yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Redução de dimensionalidade para observar a geometria\n",
        "tsne = TSNE(n_components=2, perplexity=3, random_state=42, init='pca', learning_rate='auto')\n",
        "vetores_2d = tsne.fit_transform(vetores)\n",
        "\n",
        "# Plotagem\n",
        "plt.figure(figsize=(10, 6))\n",
        "for i, label in enumerate(labels):\n",
        "    color = 'blue' if label == 1 else 'red'\n",
        "    marker = 'o' if label == 1 else 'x'\n",
        "    plt.scatter(vetores_2d[i, 0], vetores_2d[i, 1], c=color, marker=marker, s=100)\n",
        "    plt.text(vetores_2d[i, 0] + 0.1, vetores_2d[i, 1] + 0.1, f\"Frase {i}\", fontsize=9)\n",
        "\n",
        "plt.title(\"Visualização Geometrica: Polo Positivo (Azul) vs Negativo (Vermelho)\")\n",
        "plt.grid(True, linestyle= '--', alpha=0.6)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wUi6TdgDIDs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# 1. Preparação dos Tensores para o Trinamento\n",
        "# Trandirmamos nossas frases e labels em tensores do pyTorch\n",
        "\n",
        "inputs = tokenizer(frases, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
        "labels_tensor = torch.tensor(labels).to(device)\n",
        "\n",
        "# Adicionamos uma camada linear simples (Cabeça de Classificação) no topo do BERT\n",
        "# Ela será responsável por encontra o hiperplano de separação\n",
        "classifier = nn.Linear(768, 2).to(device)\n",
        "optimizer = optim.Adam(list(model.parameters()) + list(classifier.parameters()), lr=2e-5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def plot_current_state(title):\n",
        "    \"\"\"Função para capturar e plotar o estado geométrico atual\"\"\"\n",
        "    voteres_atuais = get_embeddings(frases)\n",
        "    tsne - TSNE(n_components=2, perplexity=3, random_state=42 init='pca', learning_rate='auto')\n",
        "    vis = tsne.fit_transform(vetores_2d)\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    for i, label in enumerate(labels):\n",
        "        color = 'blue' if label == 1 else 'red'\n",
        "        plt.scatter(vis[i, 0], vis[i, 1], c=color, s=100, edgecolors='black')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "    # --- ESTADO 1: ANTES DO TREINAMENTO ---\n",
        "    print(\"Visualizando Geometria Inicial (Conhecimeto Prévio)...\")\n",
        "    plot_current_state(\"EStado Inicial: Espaço Sêmantico Genérico\")\n",
        "\n",
        "    # --- PASSO DE TREINAMENTO (Deformação do Hiperplano) ---\n",
        "    print(\"\\nIniciando ajuste fina das matrizes...\")\n",
        "    model.train()\n",
        "    for epoch in range(10): # Rodamos 10 iterações para ver o movimento claro\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward: Passando os dados pela rede\n",
        "    outputs = model(**inputs)\n",
        "    cls_vectors = outputs.last_hidden_state[:, 0, :] # Vetores CLS (Lógica vetorial)\n",
        "    logits = classifier(cls_vectors) # Projeção no Hiperplano de Decisão\n",
        "\n",
        "    loss = criterion(logits, labels_tensor)\n",
        "\n",
        "    # Backward: Calculando a força (gradiente) para mover os vetores\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        print(f\"Época {epoch+1} - Erro (Loss): {loss.item():.4f}\")\n",
        "\n",
        "    # --- ESTADO 2: DEPOIS DO TREINAMENTO ---\n",
        "\n",
        "    print(\"\\nVisualizando Geometria Final (Espaço Otimizado)...\")\n",
        "    plot_current_state(\"Estado Final: Hiperplano Ajustado Pólos Separados)\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-8QtlHGuPvD2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}